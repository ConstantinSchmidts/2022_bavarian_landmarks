{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXoVEJDAvs5q"
      },
      "source": [
        "# Train a German named entity recognition with spaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXshX8ACwi-T"
      },
      "source": [
        "\n",
        "\n",
        "### Load spaCy and the German transformer pipeline https://spacy.io/models/de#de_dep_news_trf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rss9pQjTvmjk"
      },
      "outputs": [],
      "source": [
        "!pip install -U pip setuptools wheel\n",
        "!pip install -U spacy==3.3\n",
        "!pip install -U cuda111 transformers lookups\n",
        "!pip install -U spacy-transformers\n",
        "!python -m spacy download de_dep_news_trf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5ZCpP-cJTn4"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "lwN4tgsbXqsb",
        "outputId": "42f9fc5f-ae8f-4dbe-d5c9-74d72d1d0eec"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Log in to your W&B account\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFY5eyLs2pU2"
      },
      "outputs": [],
      "source": [
        "# If it does not work find out the correct cuda version\n",
        "# !nvcc --version\n",
        "\n",
        "# Test cupy\n",
        "import cupy\n",
        "a = cupy.zeros((1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y1_Pv-4HQbp",
        "outputId": "38bd972e-433b-4fdb-929a-4e6e33c86a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r⠙ Loading compatibility table...\r\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
            "\u001b[1m\n",
            "================= Installed pipeline packages (spaCy v3.3.0) =================\u001b[0m\n",
            "\u001b[38;5;4mℹ spaCy installation: /usr/local/lib/python3.7/dist-packages/spacy\u001b[0m\n",
            "\n",
            "NAME              SPACY                 VERSION                            \n",
            "de_dep_news_trf   >=3.3.0.dev0,<3.4.0   \u001b[38;5;2m3.3.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "en_core_web_sm    >=3.3.0.dev0,<3.4.0   \u001b[38;5;2m3.3.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz2ptNPryJOl"
      },
      "source": [
        "### Upload train.spacy, valid.spacy and base_config_trf_spacy32.cfg to folder data and check config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BfvqdtFVfMR"
      },
      "source": [
        " Manually change the train and valid paths in config_trf.cfg to /content/train.spacy and /content/dev.spacy.\n",
        "\n",
        "To use Weights and Biases to track the experiment and upload your dataset to W&B and track versions of it, add this to the config:\n",
        "\n",
        "```\n",
        "[training.logger]\n",
        "@loggers = \"spacy.WandbLogger.v4\"\n",
        "project_name = 'ner_lm_trf'\n",
        "remove_config_values = []\n",
        "log_dataset_dir = \"./assets\"\n",
        "```\n",
        "\n",
        "see https://pypi.org/project/spacy-loggers/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe7XHEPWyId0",
        "outputId": "20dd281d-8bd8-40b1-801e-31a5a9c8cb04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config_trf_32.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config_trf_32.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "### Create config.cfg https://spacy.io/usage/training \n",
        "!python -m spacy init fill-config base_config_trf_spacy32.cfg config_trf_32.cfg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mSUDRilJfi7",
        "outputId": "94d0bc49-acf4-433c-8987-bcf8d6065b86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m\n",
            "============================ Data file validation ============================\u001b[0m\n",
            "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
            "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
            "\u001b[1m\n",
            "=============================== Training stats ===============================\u001b[0m\n",
            "Language: de\n",
            "Training pipeline: transformer, ner\n",
            "5159 training docs\n",
            "1291 evaluation docs\n",
            "\u001b[38;5;2m✔ No overlap between training and evaluation data\u001b[0m\n",
            "\u001b[1m\n",
            "============================== Vocab & Vectors ==============================\u001b[0m\n",
            "\u001b[38;5;4mℹ 78661 total word(s) in the data (15084 unique)\u001b[0m\n",
            "\u001b[38;5;4mℹ No word vectors present in the package\u001b[0m\n",
            "\u001b[1m\n",
            "========================== Named Entity Recognition ==========================\u001b[0m\n",
            "\u001b[38;5;4mℹ 1 label(s)\u001b[0m\n",
            "0 missing value(s) (tokens with '-' label)\n",
            "\u001b[38;5;2m✔ Good amount of examples for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
            "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Summary ==================================\u001b[0m\n",
            "\u001b[38;5;2m✔ 7 checks passed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy debug data config_trf_32.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foAEbUnIKZmy"
      },
      "source": [
        "### Activate GPU in colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8B47kp5q1rxT",
        "outputId": "eb16e2c2-1998-4915-9f5b-4480e16dab54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "spacy.require_gpu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebroZtISxAij"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOKmoyDjxaeA",
        "outputId": "b0d3e7ef-d46f-4e8b-bdcd-3c1a6f969f84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: ner_lm_de_trf\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-22 08:11:08,378] [INFO] Set up nlp object from config\n",
            "[2022-07-22 08:11:08,937] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-22 08:11:08,942] [INFO] Created vocabulary\n",
            "[2022-07-22 08:11:08,943] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-07-22 08:11:20,247] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcofoers\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220722_081120-3j4cab8x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33meffortless-resonance-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/cofoers/%27ner_lm_trf%27\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/cofoers/%27ner_lm_trf%27/runs/3j4cab8x\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         811.62    661.43    0.57    0.32    2.33    0.01\n",
            "  2     200       11756.15  14546.86   78.97   75.18   83.16    0.79\n",
            "  5     400         407.74   1798.70   81.94   85.39   78.76    0.82\n",
            "  8     600         164.64   1304.94   80.66   74.40   88.08    0.81\n",
            " 11     800         129.44   1198.66   80.77   79.95   81.61    0.81\n",
            " 13    1000          69.94   1082.33   82.12   79.90   84.46    0.82\n",
            " 16    1200          73.58   1071.31   83.71   81.07   86.53    0.84\n",
            " 19    1400          33.55    959.22   83.58   87.75   79.79    0.84\n",
            " 21    1600          65.59   1002.91   83.33   86.59   80.31    0.83\n",
            " 24    1800          51.33    907.79   84.67   82.20   87.31    0.85\n",
            " 27    2000          23.99    870.59   84.17   83.63   84.72    0.84\n",
            " 30    2200          31.96    810.62   83.86   82.29   85.49    0.84\n",
            " 32    2400          37.06    816.83   82.59   84.14   81.09    0.83\n",
            " 35    2600          42.17    785.11   85.39   83.79   87.05    0.85\n",
            " 38    2800          25.71    688.88   84.29   85.19   83.42    0.84\n",
            " 40    3000          40.81    682.91   84.18   81.06   87.56    0.84\n",
            " 43    3200          38.82    649.00   83.18   86.55   80.05    0.83\n",
            " 46    3400          29.56    589.91   83.96   84.51   83.42    0.84\n",
            " 48    3600          43.75    568.30   84.84   83.46   86.27    0.85\n",
            " 51    3800          62.53    537.71   82.71   80.10   85.49    0.83\n",
            " 54    4000          35.86    511.39   83.99   83.04   84.97    0.84\n",
            " 56    4200         120.43    509.36   82.98   83.86   82.12    0.83\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           ents_f ▁▇████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           ents_p ▁▇█▇▇▇▇████████▇███▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           ents_r ▁█▇█▇██▇▇███▇███▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss_ner ▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss_transformer ▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            score ▁▇████████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            speed █▅▅▄▅▄▄▃▅▁▄▅▄▅▃▅▅▄▄▄▅▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        token_acc ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          token_f ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          token_p ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          token_r ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           ents_f 0.82984\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           ents_p 0.83862\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           ents_r 0.82124\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss_ner 509.36127\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: loss_transformer 120.42612\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            score 0.82984\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            speed 4716.17373\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        token_acc 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          token_f 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          token_p 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          token_r 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33meffortless-resonance-3\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/cofoers/%27ner_lm_trf%27/runs/3j4cab8x\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220722_081120-3j4cab8x/logs\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "ner_lm_de_trf/model-last\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config_trf_32.cfg --output ./ner_lm_de_trf --gpu-id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubz5v0KHagTJ"
      },
      "source": [
        "### Zip the folder with the best model and download it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpsG93BBI385",
        "outputId": "d17257b0-b9df-4278-87a3-9a16f89ff826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/ner_lm_de_trf/model-best/ (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/tokenizer (deflated 84%)\n",
            "  adding: content/ner_lm_de_trf/model-best/meta.json (deflated 57%)\n",
            "  adding: content/ner_lm_de_trf/model-best/vocab/ (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/vocab/vectors (deflated 45%)\n",
            "  adding: content/ner_lm_de_trf/model-best/vocab/strings.json (deflated 74%)\n",
            "  adding: content/ner_lm_de_trf/model-best/vocab/lookups.bin (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/vocab/vectors.cfg (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/vocab/key2row (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/config.cfg (deflated 61%)\n",
            "  adding: content/ner_lm_de_trf/model-best/transformer/ (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/transformer/cfg (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/transformer/model (deflated 7%)\n",
            "  adding: content/ner_lm_de_trf/model-best/ner/ (stored 0%)\n",
            "  adding: content/ner_lm_de_trf/model-best/ner/cfg (deflated 33%)\n",
            "  adding: content/ner_lm_de_trf/model-best/ner/model (deflated 8%)\n",
            "  adding: content/ner_lm_de_trf/model-best/ner/moves (deflated 38%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/file.zip /content/ner_lm_de_trf/model-best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6fggJQWRj-wM",
        "outputId": "b8c32a2c-1645-45b2-86a3-b0e2223ac107"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_773477e8-5358-433d-8b09-3fc6e10d0b62\", \"file.zip\", 405640906)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uEvLgqqv1NZ"
      },
      "source": [
        "Upload test.spacy and evaluate model performance on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJpVhxrXHiVm"
      },
      "outputs": [],
      "source": [
        "# Evaluate a currently trained model\n",
        "!python -m spacy evaluate /content/ner_lm_de_trf/model-best /content/test --gold-preproc --gpu-id 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('.lm_ner_env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "7f9db098c55defaeb2a20ca82dedb9844393a5d5e2bc9ac630bee6686a6a8978"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
